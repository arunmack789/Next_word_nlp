{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Next_word_pred.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sh4Tj_DJpGN"
      },
      "source": [
        "#pacakeges import\r\n",
        "from numpy import array\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, LSTM, Embedding\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIyYOp9yDnxu"
      },
      "source": [
        "paragraph = \"\"\" Taking over a Western group would give an Indian firm essential insight into , say , the UK Government 's attitude on benefit payment systems , or Tesco 's desire to refine its supply chain , the deal cheerleaders say . \\n \r\n",
        "Mr. Naughton said he couldn 't confirm that American customers would get a transmission option , or even that the drivetrain would be identical to other CR-Z versions . \\n\r\n",
        "More strikingly , many senior clerics support and sponsor Islamic centres in the UK and see London as one of the most important hubs for Shiaism . \\n\r\n",
        "In traditional prostate surgery , the abdomen is opened and the prostate gland exposed and surgically removed . \"\"\"\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "incEhUg3yhCM",
        "outputId": "fb9d1df0-108d-4f50-c7c6-bcc2b28ce080"
      },
      "source": [
        "#data read\r\n",
        "tokenizer = Tokenizer()\r\n",
        "tokenizer.fit_on_texts([paragraph])\r\n",
        "encode_data = tokenizer.texts_to_sequences([paragraph])[0]\r\n",
        "print(encode_data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[13, 14, 4, 15, 16, 3, 17, 18, 19, 20, 21, 22, 23, 5, 1, 6, 24, 7, 25, 26, 27, 28, 29, 8, 30, 7, 31, 9, 32, 33, 34, 35, 1, 36, 37, 5, 38, 39, 40, 41, 42, 43, 44, 10, 45, 46, 3, 47, 4, 48, 49, 8, 50, 10, 1, 51, 3, 52, 53, 9, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 2, 64, 65, 66, 11, 1, 6, 2, 67, 68, 69, 70, 71, 1, 72, 73, 74, 75, 76, 11, 77, 12, 78, 1, 79, 80, 81, 2, 1, 12, 82, 83, 2, 84, 85]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bp8p6K6sp8v",
        "outputId": "23d47e5d-5023-4788-9451-670e549955d6"
      },
      "source": [
        "#vocubalary size\r\n",
        "vocab_size = len(tokenizer.word_index) + 1\r\n",
        "print(\"Vocabulary Size:\" + str(vocab_size))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size:86\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfhWoJZzvBgl"
      },
      "source": [
        "#create word into sequenes\r\n",
        "sequences = list()\r\n",
        "for i in range(1,len(encode_data)):\r\n",
        "  sequence = encode_data[i-1:i+1]\r\n",
        "  sequences.append(sequence)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9iWUkzx0oF-",
        "outputId": "25b04c03-44b0-46e6-818c-dec0a6366030"
      },
      "source": [
        "print(\"Total sequneces:\" + str(len(sequences)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total sequneces:104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgSdvJ9h1Ex8",
        "outputId": "6d5056bc-16a8-4a01-8ba9-0f9076e253af"
      },
      "source": [
        "sequences"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[13, 14],\n",
              " [14, 4],\n",
              " [4, 15],\n",
              " [15, 16],\n",
              " [16, 3],\n",
              " [3, 17],\n",
              " [17, 18],\n",
              " [18, 19],\n",
              " [19, 20],\n",
              " [20, 21],\n",
              " [21, 22],\n",
              " [22, 23],\n",
              " [23, 5],\n",
              " [5, 1],\n",
              " [1, 6],\n",
              " [6, 24],\n",
              " [24, 7],\n",
              " [7, 25],\n",
              " [25, 26],\n",
              " [26, 27],\n",
              " [27, 28],\n",
              " [28, 29],\n",
              " [29, 8],\n",
              " [8, 30],\n",
              " [30, 7],\n",
              " [7, 31],\n",
              " [31, 9],\n",
              " [9, 32],\n",
              " [32, 33],\n",
              " [33, 34],\n",
              " [34, 35],\n",
              " [35, 1],\n",
              " [1, 36],\n",
              " [36, 37],\n",
              " [37, 5],\n",
              " [5, 38],\n",
              " [38, 39],\n",
              " [39, 40],\n",
              " [40, 41],\n",
              " [41, 42],\n",
              " [42, 43],\n",
              " [43, 44],\n",
              " [44, 10],\n",
              " [10, 45],\n",
              " [45, 46],\n",
              " [46, 3],\n",
              " [3, 47],\n",
              " [47, 4],\n",
              " [4, 48],\n",
              " [48, 49],\n",
              " [49, 8],\n",
              " [8, 50],\n",
              " [50, 10],\n",
              " [10, 1],\n",
              " [1, 51],\n",
              " [51, 3],\n",
              " [3, 52],\n",
              " [52, 53],\n",
              " [53, 9],\n",
              " [9, 54],\n",
              " [54, 55],\n",
              " [55, 56],\n",
              " [56, 57],\n",
              " [57, 58],\n",
              " [58, 59],\n",
              " [59, 60],\n",
              " [60, 61],\n",
              " [61, 62],\n",
              " [62, 63],\n",
              " [63, 2],\n",
              " [2, 64],\n",
              " [64, 65],\n",
              " [65, 66],\n",
              " [66, 11],\n",
              " [11, 1],\n",
              " [1, 6],\n",
              " [6, 2],\n",
              " [2, 67],\n",
              " [67, 68],\n",
              " [68, 69],\n",
              " [69, 70],\n",
              " [70, 71],\n",
              " [71, 1],\n",
              " [1, 72],\n",
              " [72, 73],\n",
              " [73, 74],\n",
              " [74, 75],\n",
              " [75, 76],\n",
              " [76, 11],\n",
              " [11, 77],\n",
              " [77, 12],\n",
              " [12, 78],\n",
              " [78, 1],\n",
              " [1, 79],\n",
              " [79, 80],\n",
              " [80, 81],\n",
              " [81, 2],\n",
              " [2, 1],\n",
              " [1, 12],\n",
              " [12, 82],\n",
              " [82, 83],\n",
              " [83, 2],\n",
              " [2, 84],\n",
              " [84, 85]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qB-KqjH1ga8"
      },
      "source": [
        "sequences = array(sequences)\r\n",
        "X, y = sequences[:,0], sequences[:,1] # split sequences data as X and y"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5uKbamo14ej",
        "outputId": "2ba1bd21-bae1-44eb-a4f7-e1c97434bb56"
      },
      "source": [
        "len(X)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhr3hHZavL1P"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APv1Pjvg16uG",
        "outputId": "6b878777-d944-4075-929e-7282a41fdd73"
      },
      "source": [
        "len(y)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieb8Tws12FJd",
        "outputId": "d2d41ac8-7031-4152-8fc7-7925860c2406"
      },
      "source": [
        "#one_encode\r\n",
        "y = to_categorical(y, num_classes=vocab_size)\r\n",
        "y"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgZ4nae12a2n",
        "outputId": "67772d32-3627-4579-b84c-9072b92bb340"
      },
      "source": [
        "#model design\r\n",
        "model = Sequential()\r\n",
        "model.add(Embedding(vocab_size,104,input_length=1))\r\n",
        "model.add(LSTM(50))\r\n",
        "model.add(Dense(vocab_size,activation=\"softmax\"))\r\n",
        "print(model.summary())"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 1, 104)            8944      \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 50)                31000     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 86)                4386      \n",
            "=================================================================\n",
            "Total params: 44,330\n",
            "Trainable params: 44,330\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11YRo6nB3mPW"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3Z6icG34UfB",
        "outputId": "129f6e95-a73a-4c3e-868a-f065c2d64f28"
      },
      "source": [
        "model.fit(X,y,epochs=100) # training"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 1s 5ms/step - loss: 4.4542 - accuracy: 0.0365\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.4490 - accuracy: 0.0853\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.4448 - accuracy: 0.1647\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.4403 - accuracy: 0.2917\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.4355 - accuracy: 0.2667\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.4320 - accuracy: 0.3419\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.4273 - accuracy: 0.3667\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.4208 - accuracy: 0.3903\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.4162 - accuracy: 0.3889\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.4076 - accuracy: 0.4070\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.4024 - accuracy: 0.4063\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.3948 - accuracy: 0.4356\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.3860 - accuracy: 0.5038\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.3780 - accuracy: 0.5156\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.3678 - accuracy: 0.5550\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.3584 - accuracy: 0.5693\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.3443 - accuracy: 0.6020\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.3298 - accuracy: 0.6430\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.3145 - accuracy: 0.6438\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.3006 - accuracy: 0.5972\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.2725 - accuracy: 0.6204\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.2476 - accuracy: 0.6048\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.2231 - accuracy: 0.5901\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.2034 - accuracy: 0.6054\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.1656 - accuracy: 0.6176\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.1307 - accuracy: 0.5898\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.1011 - accuracy: 0.6155\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.0412 - accuracy: 0.6454\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 3.9950 - accuracy: 0.5596\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 3.9577 - accuracy: 0.5832\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 3.9096 - accuracy: 0.5234\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 3.8582 - accuracy: 0.5619\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 3.7543 - accuracy: 0.5599\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 3.6885 - accuracy: 0.5571\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 3.6342 - accuracy: 0.5438\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 3.5647 - accuracy: 0.5327\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 3.4232 - accuracy: 0.5119\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 3.4087 - accuracy: 0.4650\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 3.3355 - accuracy: 0.5345\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 3.2915 - accuracy: 0.5084\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 3.2366 - accuracy: 0.5126\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 3.0982 - accuracy: 0.5283\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 3.0594 - accuracy: 0.5220\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.9713 - accuracy: 0.5675\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.8319 - accuracy: 0.5800\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.7381 - accuracy: 0.6023\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.7281 - accuracy: 0.5486\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.5137 - accuracy: 0.6744\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.5599 - accuracy: 0.6796\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.4570 - accuracy: 0.6717\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.4434 - accuracy: 0.6989\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.3199 - accuracy: 0.7469\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.2528 - accuracy: 0.8220\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.0279 - accuracy: 0.7990\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.0509 - accuracy: 0.8206\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.0214 - accuracy: 0.8116\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.8031 - accuracy: 0.8314\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.7735 - accuracy: 0.8353\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.7021 - accuracy: 0.8217\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.5993 - accuracy: 0.8342\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.5311 - accuracy: 0.8103\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.4223 - accuracy: 0.8144\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.4214 - accuracy: 0.8134\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.3484 - accuracy: 0.8068\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.2892 - accuracy: 0.7946\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.1676 - accuracy: 0.8040\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1208 - accuracy: 0.8134\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0072 - accuracy: 0.8457\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9566 - accuracy: 0.8238\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9329 - accuracy: 0.8353\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9154 - accuracy: 0.8165\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8703 - accuracy: 0.7988\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8145 - accuracy: 0.8113\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7951 - accuracy: 0.8082\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7424 - accuracy: 0.8290\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7368 - accuracy: 0.8123\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6883 - accuracy: 0.8113\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6734 - accuracy: 0.8165\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6438 - accuracy: 0.8248\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6191 - accuracy: 0.8123\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.8078\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5425 - accuracy: 0.8571\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6222 - accuracy: 0.7978\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5539 - accuracy: 0.8155\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5707 - accuracy: 0.7918\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5763 - accuracy: 0.8175\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5253 - accuracy: 0.8168\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5116 - accuracy: 0.8207\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5057 - accuracy: 0.8165\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.8175\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5306 - accuracy: 0.8175\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.8113\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4762 - accuracy: 0.8290\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4740 - accuracy: 0.8168\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4723 - accuracy: 0.8165\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4931 - accuracy: 0.8103\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8436\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4543 - accuracy: 0.8071\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4702 - accuracy: 0.8144\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.8134\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe4b4fa6e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S87Qsd_g6Zt6"
      },
      "source": [
        "def generate_sequences(model,tokenizer,enter_text,n_pred): #generate sequences to next word\r\n",
        "  in_text, result = enter_text, enter_text\r\n",
        "  #generate fixed no of Npred\r\n",
        "  for _ in range(n_pred):\r\n",
        "    #encode text as integer\r\n",
        "    encode = tokenizer.texts_to_sequences([in_text])[0]\r\n",
        "    #print([in_text])\r\n",
        "    encode = array(encode)\r\n",
        "    #yhat predicated\r\n",
        "    y_hat = model.predict_classes(encode)\r\n",
        "    #map outword to index\r\n",
        "    output_word = '' \r\n",
        "    for word, index in tokenizer.word_index.items():\r\n",
        "      if index == y_hat:\r\n",
        "        output_word = word\r\n",
        "        break\r\n",
        "    in_text, result = output_word, result + ' ' + output_word\r\n",
        "  return result\r\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-Jj5hXR-OfK",
        "outputId": "281156d1-4e7d-4227-9e70-ae816fec745f"
      },
      "source": [
        "for word, index in tokenizer.word_index.items(): \r\n",
        "  print(index)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3wTx86NOT4F"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrDZLiMn8JWN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae343891-0a3f-44ea-a5d6-18d6f5d379f9"
      },
      "source": [
        "print(generate_sequences(model,tokenizer,'Taking',9))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Taking over a western group would be identical to refine\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}